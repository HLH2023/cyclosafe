# 模型部署指南

本文档详细说明如何将训练好的机器学习模型部署到微信小程序中。

---

## 目录

1. [部署概述](#1-部署概述)
2. [模型转换](#2-模型转换)
3. [小程序集成](#3-小程序集成)
4. [推理实现](#4-推理实现)
5. [性能优化](#5-性能优化)
6. [版本管理](#6-版本管理)
7. [更新策略](#7-更新策略)

---

## 1. 部署概述

### 1.1 部署架构

```
训练完成的模型 (sklearn .pkl)
    ↓
转换为 TensorFlow/Keras 格式
    ↓
转换为 TensorFlow.js 格式
    ↓
上传到云存储/CDN
    ↓
小程序下载并加载模型
    ↓
本地推理
```

### 1.2 技术选型

| 方案 | 优点 | 缺点 | 推荐度 |
|-----|------|------|-------|
| **方案A: TensorFlow.js** | 官方支持、功能完整 | 模型大 | ⭐⭐⭐⭐ |
| **方案B: ONNX.js** | 模型小、速度快 | 小程序支持有限 | ⭐⭐⭐ |
| **方案C: 自定义推理** | 模型最小 | 功能受限 | ⭐⭐⭐⭐⭐ |

**推荐:** 使用方案C（自定义推理），将Random Forest模型参数导出为JSON，在小程序中实现轻量级推理引擎。

---

## 2. 模型转换

### 2.1 导出Random Forest参数

由于Random Forest模型较大（通常>5MB），我们采用轻量级方案：导出模型参数为JSON。

```python
# training/export_model.py
import joblib
import json
import numpy as np

class ModelExporter:
    """模型导出器"""

    def __init__(self, model_path):
        self.model = joblib.load(model_path)

    def export_to_json(self, output_path='model_params.json'):
        """导出为JSON格式（轻量级）"""

        if not hasattr(self.model, 'estimators_'):
            raise ValueError("模型必须是RandomForestClassifier")

        # 提取关键参数
        model_params = {
            'type': 'random_forest',
            'n_estimators': self.model.n_estimators,
            'n_features': self.model.n_features_in_,
            'n_classes': self.model.n_classes_,
            'trees': []
        }

        # 导出每棵树（简化版）
        for tree in self.model.estimators_[:10]:  # 只导出前10棵树（减小体积）
            tree_data = self._export_tree(tree.tree_)
            model_params['trees'].append(tree_data)

        # 保存
        with open(output_path, 'w') as f:
            json.dump(model_params, f)

        print(f"✅ 模型已导出: {output_path}")
        return output_path

    def _export_tree(self, tree):
        """导出单棵决策树"""

        return {
            'feature': tree.feature.tolist(),
            'threshold': tree.threshold.tolist(),
            'children_left': tree.children_left.tolist(),
            'children_right': tree.children_right.tolist(),
            'value': tree.value.tolist()
        }

    def export_feature_config(self, output_path='feature_config.json'):
        """导出特征提取配置"""

        config = {
            'window_size': 100,
            'overlap': 50,
            'sampling_rate': 50,
            'feature_list': [
                'mean', 'std', 'min', 'max', 'rms',
                'skewness', 'kurtosis', 'energy'
            ]
        }

        with open(output_path, 'w') as f:
            json.dump(config, f, indent=2)

        print(f"✅ 特征配置已导出: {output_path}")

# 使用示例
if __name__ == "__main__":
    exporter = ModelExporter('models/fall_detection_rf.pkl')
    exporter.export_to_json('models/model_params.json')
    exporter.export_feature_config('models/feature_config.json')
```

### 2.2 方案B：TensorFlow.js转换（可选）

如果使用深度学习模型（CNN-LSTM），可使用TensorFlow.js：

```python
# training/export_tfjs.py
import tensorflow as tf
import tensorflowjs as tfjs

def export_to_tfjs(keras_model_path, output_dir):
    """转换Keras模型为TensorFlow.js格式"""

    # 加载Keras模型
    model = tf.keras.models.load_model(keras_model_path)

    # 转换并保存
    tfjs.converters.save_keras_model(model, output_dir)

    print(f"✅ TensorFlow.js模型已保存: {output_dir}")

# 使用
export_to_tfjs('models/fall_detection_cnn.h5', 'models/tfjs_model')
```

---

## 3. 小程序集成

### 3.1 创建ML模型服务

**文件路径:** `/services/mlModel.js`

```javascript
/**
 * 机器学习模型服务
 * 实现轻量级Random Forest推理
 */

class MLFallDetector {
  constructor() {
    this.model = null;
    this.featureConfig = null;
    this.isLoaded = false;
  }

  /**
   * 加载模型
   */
  async loadModel(modelUrl, featureConfigUrl) {
    try {
      console.log('[MLModel] 开始加载模型...');

      // 加载模型参数
      const modelResponse = await uni.request({
        url: modelUrl,
        method: 'GET'
      });

      if (modelResponse.statusCode === 200) {
        this.model = modelResponse.data;
      } else {
        throw new Error('模型加载失败');
      }

      // 加载特征配置
      const configResponse = await uni.request({
        url: featureConfigUrl,
        method: 'GET'
      });

      if (configResponse.statusCode === 200) {
        this.featureConfig = configResponse.data;
      } else {
        throw new Error('特征配置加载失败');
      }

      this.isLoaded = true;
      console.log('[MLModel] 模型加载成功');

    } catch (err) {
      console.error('[MLModel] 模型加载失败', err);
      throw err;
    }
  }

  /**
   * 预测
   * @param {Array} windowData - 窗口数据 [{acc: {x,y,z}, gyro: {x,y,z}}, ...]
   * @returns {number} 摔倒概率 (0-1)
   */
  predict(windowData) {
    if (!this.isLoaded) {
      throw new Error('模型未加载');
    }

    if (windowData.length < this.featureConfig.window_size) {
      throw new Error('数据长度不足');
    }

    // 1. 提取特征
    const features = this.extractFeatures(windowData);

    // 2. Random Forest推理
    const probability = this.randomForestPredict(features);

    return probability;
  }

  /**
   * 提取特征（简化版）
   */
  extractFeatures(windowData) {
    const features = [];

    // 提取加速度和角速度数据
    const accX = windowData.map(d => d.acc.x);
    const accY = windowData.map(d => d.acc.y);
    const accZ = windowData.map(d => d.acc.z);
    const gyroX = windowData.map(d => d.gyro.x);
    const gyroY = windowData.map(d => d.gyro.y);
    const gyroZ = windowData.map(d => d.gyro.z);

    const allSignals = [accX, accY, accZ, gyroX, gyroY, gyroZ];

    // 对每个轴提取基本统计特征
    allSignals.forEach(signal => {
      features.push(this.mean(signal));      // 均值
      features.push(this.std(signal));       // 标准差
      features.push(Math.min(...signal));    // 最小值
      features.push(Math.max(...signal));    // 最大值
      features.push(this.rms(signal));       // RMS
    });

    // 合成特征
    const accMag = windowData.map(d =>
      Math.sqrt(d.acc.x**2 + d.acc.y**2 + d.acc.z**2)
    );
    const gyroMag = windowData.map(d =>
      Math.sqrt(d.gyro.x**2 + d.gyro.y**2 + d.gyro.z**2)
    );

    features.push(this.mean(accMag));
    features.push(Math.max(...accMag));
    features.push(this.mean(gyroMag));
    features.push(Math.max(...gyroMag));

    return features;
  }

  /**
   * Random Forest推理
   */
  randomForestPredict(features) {
    const trees = this.model.trees;
    let votes = 0;

    // 对每棵树进行预测
    trees.forEach(tree => {
      const prediction = this.predictTree(tree, features);
      votes += prediction;
    });

    // 返回概率（投票比例）
    return votes / trees.length;
  }

  /**
   * 单棵决策树预测
   */
  predictTree(tree, features) {
    let nodeIndex = 0;

    // 遍历决策树
    while (tree.children_left[nodeIndex] !== -1) {
      const feature = tree.feature[nodeIndex];
      const threshold = tree.threshold[nodeIndex];

      if (features[feature] <= threshold) {
        nodeIndex = tree.children_left[nodeIndex];
      } else {
        nodeIndex = tree.children_right[nodeIndex];
      }
    }

    // 返回叶节点的值（0或1）
    const value = tree.value[nodeIndex];
    return value[0][1] > value[0][0] ? 1 : 0;
  }

  // ========== 数学工具函数 ==========

  mean(arr) {
    return arr.reduce((a, b) => a + b, 0) / arr.length;
  }

  std(arr) {
    const m = this.mean(arr);
    const variance = arr.reduce((sum, val) => sum + (val - m) ** 2, 0) / arr.length;
    return Math.sqrt(variance);
  }

  rms(arr) {
    const sumSquares = arr.reduce((sum, val) => sum + val ** 2, 0);
    return Math.sqrt(sumSquares / arr.length);
  }
}

// 导出单例
const mlModel = new MLFallDetector();

export default mlModel;
```

### 3.2 在骑行页面集成

修改 `pages/riding/riding.vue`，集成ML模型：

```javascript
import mlModel from '@/services/mlModel.js';

// 在 onLoad 中加载模型
onLoad(async () => {
  try {
    await mlModel.loadModel(
      'https://your-cdn.com/models/model_params.json',
      'https://your-cdn.com/models/feature_config.json'
    );
    console.log('ML模型加载成功');
  } catch (err) {
    console.error('ML模型加载失败', err);
    // 降级到阈值算法
  }
});

// 混合检测策略
const detectFall = (windowData) => {
  // 1. 快速阈值预检
  if (!quickThresholdCheck(windowData)) {
    return false;
  }

  // 2. ML模型精确判断
  try {
    const probability = mlModel.predict(windowData);
    return probability > 0.7; // 阈值可调
  } catch (err) {
    console.error('ML推理失败，降级到阈值算法', err);
    return thresholdBasedDetection(windowData);
  }
};
```

---

## 4. 推理实现

### 4.1 实时推理管道

```javascript
/**
 * 实时摔倒检测服务
 */
class RealtimeFallDetectionService {
  constructor() {
    this.buffer = [];
    this.windowSize = 100;
    this.mlModel = mlModel;
    this.thresholdDetector = thresholdDetector;
  }

  /**
   * 添加传感器数据
   */
  addSensorData(acc, gyro) {
    this.buffer.push({ acc, gyro, timestamp: Date.now() });

    // 维护窗口大小
    if (this.buffer.length > this.windowSize) {
      this.buffer.shift();
    }

    // 窗口满后进行检测
    if (this.buffer.length === this.windowSize) {
      this.detect();
    }
  }

  /**
   * 混合检测策略
   */
  detect() {
    // 策略1: 快速阈值预检（节省计算）
    const quickCheck = this.quickCheck();
    if (!quickCheck) {
      return false; // 明显不是摔倒，跳过ML
    }

    // 策略2: ML模型精确判断
    try {
      const probability = this.mlModel.predict(this.buffer);

      if (probability > 0.7) {
        this.onFallDetected('ml', probability);
        return true;
      }
    } catch (err) {
      // ML失败，降级到阈值算法
      console.warn('ML推理失败，使用阈值算法', err);
      return this.thresholdDetector.detect(this.buffer);
    }

    return false;
  }

  /**
   * 快速阈值检查
   */
  quickCheck() {
    // 计算总加速度
    const accMagnitudes = this.buffer.map(d =>
      Math.sqrt(d.acc.x**2 + d.acc.y**2 + d.acc.z**2)
    );

    const maxAcc = Math.max(...accMagnitudes);

    // 如果加速度小于阈值，肯定不是摔倒
    return maxAcc > 12.0; // m/s²
  }

  /**
   * 摔倒检测回调
   */
  onFallDetected(method, confidence) {
    console.warn(`[检测到摔倒] 方法:${method}, 置信度:${confidence.toFixed(3)}`);

    // 触发警告
    uni.vibrateLong();
    uni.showModal({
      title: '⚠️ 摔倒检测',
      content: `检测到摔倒（置信度: ${(confidence*100).toFixed(1)}%），是否需要帮助？`
    });
  }
}

export default new RealtimeFallDetectionService();
```

---

## 5. 性能优化

### 5.1 模型压缩

```python
# 减少树的数量（准确率下降约1-2%）
def compress_model(model, n_trees=20):
    """压缩Random Forest模型"""

    compressed_estimators = model.estimators_[:n_trees]
    model.estimators_ = compressed_estimators
    model.n_estimators = n_trees

    return model

# 使用
compressed_model = compress_model(model, n_trees=20)
```

### 5.2 特征选择

```python
# 只使用最重要的特征
def select_top_features(X, y, n_features=30):
    """选择最重要的特征"""

    from sklearn.feature_selection import SelectKBest, f_classif

    selector = SelectKBest(f_classif, k=n_features)
    X_selected = selector.fit_transform(X, y)

    return X_selected, selector
```

### 5.3 小程序端优化

```javascript
// 1. 特征提取优化（只计算关键特征）
extractFeaturesOptimized(windowData) {
  const features = [];

  // 只提取最重要的特征（减少计算量）
  const accX = windowData.map(d => d.acc.x);
  const accMag = windowData.map(d =>
    Math.sqrt(d.acc.x**2 + d.acc.y**2 + d.acc.z**2)
  );

  features.push(
    this.mean(accMag),
    Math.max(...accMag),
    this.std(accMag)
  );

  return features;
}

// 2. 推理节流（避免过度计算）
const throttledDetect = throttle(this.detect, 500); // 最多0.5秒检测一次
```

### 5.4 延迟加载

```javascript
// 延迟加载模型（不阻塞启动）
setTimeout(async () => {
  await mlModel.loadModel(...);
}, 3000);
```

---

## 6. 版本管理

### 6.1 模型版本化

```javascript
// services/modelVersion.js
class ModelVersionManager {
  constructor() {
    this.currentVersion = null;
    this.modelCache = {};
  }

  /**
   * 检查更新
   */
  async checkForUpdates() {
    try {
      const response = await uni.request({
        url: 'https://api.example.com/api/model/download',
        method: 'GET'
      });

      if (response.statusCode === 200) {
        const latestVersion = response.data.data.model_version;
        const currentVersion = uni.getStorageSync('model_version');

        if (latestVersion !== currentVersion) {
          return {
            hasUpdate: true,
            latestVersion,
            modelUrl: response.data.data.model_url
          };
        }
      }

      return { hasUpdate: false };
    } catch (err) {
      console.error('检查更新失败', err);
      return { hasUpdate: false };
    }
  }

  /**
   * 下载新模型
   */
  async downloadModel(modelUrl, version) {
    uni.showLoading({ title: '更新模型中...' });

    try {
      const response = await uni.request({
        url: modelUrl,
        method: 'GET'
      });

      if (response.statusCode === 200) {
        // 保存到本地
        uni.setStorageSync('model_data', response.data);
        uni.setStorageSync('model_version', version);

        uni.showToast({
          title: '模型更新成功',
          icon: 'success'
        });

        return true;
      }
    } catch (err) {
      console.error('模型下载失败', err);
      uni.showToast({
        title: '更新失败',
        icon: 'none'
      });
      return false;
    } finally {
      uni.hideLoading();
    }
  }
}

export default new ModelVersionManager();
```

### 6.2 自动更新

```javascript
// 在App.vue的onLaunch中
import modelVersionManager from '@/services/modelVersion.js';

onLaunch(async () => {
  // 检查模型更新
  const updateInfo = await modelVersionManager.checkForUpdates();

  if (updateInfo.hasUpdate) {
    uni.showModal({
      title: '模型更新',
      content: `发现新版本 ${updateInfo.latestVersion}，是否更新？`,
      success: async (res) => {
        if (res.confirm) {
          await modelVersionManager.downloadModel(
            updateInfo.modelUrl,
            updateInfo.latestVersion
          );
        }
      }
    });
  }
});
```

---

## 7. 更新策略

### 7.1 灰度发布

```javascript
// 后端API返回
{
  "model_version": "v1.2.0",
  "rollout_percentage": 20,  // 灰度20%用户
  "model_url": "https://cdn.example.com/models/v1.2.0/model.json"
}

// 小程序端判断
const shouldUpdate = (rolloutPercentage) => {
  const userId = uni.getStorageSync('anonymous_user_id');
  const hash = simpleHash(userId);
  return (hash % 100) < rolloutPercentage;
};
```

### 7.2 A/B测试

```javascript
class ABTestManager {
  constructor() {
    this.variant = this.assignVariant();
  }

  assignVariant() {
    const userId = uni.getStorageSync('anonymous_user_id');
    const hash = simpleHash(userId);

    // 50% A组（ML模型），50% B组（阈值算法）
    return (hash % 2 === 0) ? 'A' : 'B';
  }

  getDetector() {
    if (this.variant === 'A') {
      return mlModel;
    } else {
      return thresholdDetector;
    }
  }

  logEvent(eventType, data) {
    // 上报A/B测试数据
    uni.request({
      url: 'https://api.example.com/api/ab-test/log',
      method: 'POST',
      data: {
        variant: this.variant,
        eventType,
        data,
        timestamp: Date.now()
      }
    });
  }
}
```

### 7.3 回滚机制

```javascript
// 如果新模型表现不佳，快速回滚
const rollbackModel = async () => {
  const previousVersion = uni.getStorageSync('model_version_backup');

  if (previousVersion) {
    uni.setStorageSync('model_version', previousVersion);
    uni.showToast({
      title: '已回滚到上一版本',
      icon: 'success'
    });
  }
};
```

---

## 8. 监控和日志

### 8.1 性能监控

```javascript
class PerformanceMonitor {
  logInference(duration, result) {
    console.log(`[性能] 推理耗时: ${duration}ms, 结果: ${result}`);

    // 上报统计
    if (duration > 100) {
      console.warn('[性能警告] 推理耗时过长');
    }
  }

  logAccuracy(prediction, userFeedback) {
    // 用户反馈：是否真的摔倒了
    const isCorrect = prediction === userFeedback;

    console.log(`[准确性] 预测:${prediction}, 实际:${userFeedback}, 正确:${isCorrect}`);

    // 上报到后端
    uni.request({
      url: 'https://api.example.com/api/feedback',
      method: 'POST',
      data: {
        prediction,
        userFeedback,
        timestamp: Date.now()
      }
    });
  }
}
```

---

## 总结

本文档介绍了完整的模型部署流程：

1. ✅ **模型转换**: sklearn → JSON（轻量级）
2. ✅ **小程序集成**: 实现推理引擎
3. ✅ **推理实现**: 混合检测策略
4. ✅ **性能优化**: 模型压缩、特征选择
5. ✅ **版本管理**: 自动更新、灰度发布
6. ✅ **更新策略**: A/B测试、回滚机制
7. ✅ **监控日志**: 性能监控、准确性跟踪

**关键要点:**
- 使用轻量级JSON格式部署（< 500KB）
- 混合检测策略（阈值预检 + ML精确判断）
- 优雅降级（ML失败时使用阈值算法）
- 持续优化（收集反馈、迭代模型）

---

## 下一步

1. 📊 收集足够的训练数据（100+摔倒，1000+正常）
2. 🤖 训练并评估模型
3. 📦 按照本文档部署模型
4. 🔄 持续监控和优化

祝部署顺利！🚀
